---
layout: post
title: Parsing large files using PowerShell
date: 2012-01-17 15:54:00.000000000 -07:00
categories:
- coding
- professional
tags:
- powershell
status: publish
type: post
published: true
meta:
  tumblr_agiletapir_permalink: http://agiletapir.tumblr.com/post/16027425866/parsing-large-files-using-powershell
  tumblr_agiletapir_id: '16027425866'
  _wp_old_slug: '16027425866'
  _edit_last: '5'
  _syntaxhighlighter_encoded: '1'
  _jetpack_related_posts_cache: a:1:{s:32:"8f6677c9d6b0f903e98ad32ec61f8deb";a:2:{s:7:"expires";i:1436237895;s:7:"payload";a:3:{i:0;a:1:{s:2:"id";i:532;}i:1;a:1:{s:2:"id";i:992;}i:2;a:1:{s:2:"id";i:529;}}}}
author:
  login: Chuck
  email: chuck@neontapir.com
  display_name: Chuck
  first_name: Chuck
  last_name: Durfee
excerpt: !ruby/object:Hpricot::Doc
  options: {}
---
<p>At work, I had the need to parse through a large pipe-delimited file to count the number of records whose 5th column meets and doesn’t meet my criteria.</p>
<p>[sourcecode language="powershell"]<br />
gc items.txt -readcount 1000 | `<br />
  ? { $_ -notlike &quot;HEAD&quot; } | `<br />
  % { foreach ($s in $_) { $s.split(&quot;|&quot;)[4] } } | `<br />
  group -property {$_ -ge 256} -noelement | `<br />
  ft -autosize<br />
[/sourcecode]</p>
<p>This command does what I want, returning output like this:</p>
<pre>  Count Name
  ----- ----
1129339 True
2013703 False</pre>
<p>Here’s some explanation in English, for those of you who don’t know PowerShell.</p>
<p>The first command is <strong>gc</strong> (Get-Content), which reads the file in 1000 (readcount) lines at a time.</p>
<p>The second command is <strong>?</strong> (Where-Object), which filters out the HEAD row.</p>
<p>The next command <strong>%</strong> is an alias for Foreach-Object, where object in this case is a 1000-line chunk. The inner loop is another foreach loop, which is slightly different from Foreach-Object in ways that are unimportant to the matter at hand. Point is, you can’t nest % blocks. The block of the foreach loop splits each line by pipe delimiter and returns just the 5th column (first column is numbered 0).</p>
<p>The next command in the chain is <strong>group</strong>, an alias for Group-Object, in this case we’re grouping by a calculated property, whether the output of the previous command is greater than or equal to 256. By saying “-noelement”, I’m saying I don’t need an enumerated list of the values, which in this case are unimportant.</p>
<p>Finally, we get to <strong>ft</strong> (Format-Table). It is necessary because the Count column may be over 99999, in which case the value is truncated. The option “-autosize” causes PowerShell to make it fit instead.</p>
<p>However, for a 500 MB test file, this command takes about 5.5 minutes to run as measured by Measure-Command. A typical file is over 2 GB, where waiting 20+ minutes is undesirably long.</p>
<p>I posted a query to StackOverflow for some ideas.</p>
<p>While I waited, I discovered that 2500 was the optimum value for -ReadCount, getting the command execution time down to about 3.5 minutes.</p>
<p>Within minutes, I got a helpful hint from Gisli to look into using the .NET StreamReader. Here’s what that Show-SourceCounts script looks like:</p>
<p>[sourcecode language="powershell"]<br />
param($file = $(Read-Host -prompt &quot;File&quot;))<br />
$fullName = (Get-Item &quot;$file&quot;).FullName<br />
$sr = New-Object System.IO.StreamReader(&quot;$fullName&quot;)<br />
$trueCount = 0;<br />
$falseCount = 0;<br />
while (($line = $sr.ReadLine()) -ne $null) {<br />
      if ($line -like 'HEAD|') { continue }<br />
      if ($line.split(&quot;|&quot;)[4] -ge 256) {<br />
            $trueCount++<br />
      }<br />
      else {<br />
            $falseCount++<br />
      }<br />
}<br />
$sr.Dispose()<br />
write &quot;True count:   $trueCount&quot;<br />
write &quot;False count: $falseCount&quot;<br />
[/sourcecode]</p>
<p>This script yields the same results as the first command, but in about a minute. Quite an improvement!</p>
